input {
  udp {
    port => 5044
    codec => json
  }
}
filter {
  # Parse the log message
  grok {
    match => { "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{LOGLEVEL:level}\] %{GREEDYDATA:log_message}" }
  }
  
  # Convert the timestamp to the right format
  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
    target => "@timestamp"
    remove_field => [ "timestamp" ]
  }

  # Parse the log message to extract processing time
  if [log_message] =~ /ProcessingTime/ {
    grok {
      match => { "log_message" => ".*ProcessingTime=%{NUMBER:processing_time:int}ms.*" }
    }
  }

  # Add any custom fields or transformations
  mutate {
    rename => { "log_message" => "message" }
    add_field => { "host" => "%{host}" }
  }

  # Remove fields that are not needed
  mutate {
    remove_field => ["tags", "host"]
  }
}
output {
  # file {
  #   path => "/usr/share/logstash/logs/logstash_output.log"
  #   codec => json_lines
  # }
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]  # Thay thế bằng địa chỉ và port của Elasticsearch
    index => "fe.ecommerce-%{+YYYY.MM.dd}"  # Đặt tên index Elasticsearch theo ngày
    document_type => "_doc"  # Loại tài liệu Elasticsearch
  }
  stdout { codec => rubydebug }
}